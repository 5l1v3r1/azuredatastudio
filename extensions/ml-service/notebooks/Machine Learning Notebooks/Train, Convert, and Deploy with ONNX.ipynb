{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<p align=\"center\">\n",
                "<img src =\"https://raw.githubusercontent.com/microsoft/azuredatastudio/master/src/sql/media/microsoft_logo_gray.svg?sanitize=true\" width=\"250\" align=\"center\">\n",
                "</p>\n",
                "\n",
                "# **Train, Convert, and Deploy with ONNX Runtime**\n",
                "\n",
                "In SQL Server, we support native PREDICT using ONNX Models. Currently, we only support models with **numeric data types**: int and bigint [data types](https://docs.microsoft.com/en-us/sql/t-sql/data-types/int-bigint-smallint-and-tinyint-transact-sql?view=sql-server-ver15), real and float [data types](https://docs.microsoft.com/en-us/sql/t-sql/data-types/float-and-real-transact-sql?view=sql-server-ver15). Other numeric types can be converted to types we support by using CAST and CONVERT [CAST and CONVERT](https://docs.microsoft.com/en-us/sql/t-sql/functions/cast-and-convert-transact-sql?view=sql-server-ver15). The model inputs should be structured so that each input to the model corresponds to a single SQL Server column. For example: If you are using a pandas dataframe to train a model, then each input should be a separate column to the model.\n",
                " \n",
                "ONNXMLTools enables you to convert models from different machine learning toolkits into ONNX. Currently, for numeric data types and single column inputs, the following toolkits are supported in SQL Server:\n",
                " \n",
                "* [scikit-learn](https://github.com/onnx/sklearn-onnx)\n",
                "* [Tensorflow](https://github.com/onnx/tensorflow-onnx)\n",
                "* [Keras](https://github.com/onnx/keras-onnx)\n",
                "* [CoreML](https://github.com/onnx/onnxmltools)\n",
                "* [Spark ML (experimental)](https://github.com/onnx/onnxmltools/tree/master/onnxmltools/convert/sparkml)\n",
                "* [LightGBM](https://github.com/onnx/onnxmltools)\n",
                "* [libsvm](https://github.com/onnx/onnxmltools)\n",
                "* [XGBoost](https://github.com/onnx/onnxmltools)\n",
                " \n",
                "Follow the tutorial below based on scikit-learn and using the Boston Housing [dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_boston.html). This is an example which you can follow to load other datasets as well. \n",
                "\n",
                "### **Before you begin**\n",
                "\n",
                "* Install [Azure Data Studio](https://docs.microsoft.com/sql/azure-data-studio/download) \n",
                "\n",
                "* Open Azure Data Studio and follow these steps to install the packages needed for this quickstart:\n",
                "\n",
                "    1. Open [New Notebook](https://docs.microsoft.com/sql/azure-data-studio/sql-notebooks) connected to the Python 3 Kernel. \n",
                "    1. Click on the Manage Packages and under **Add New** search for **sklearn** and install the scikit-learn package. \n",
                "    1. Also, install the **onnxmltools**, **onnxruntime**, **skl2onnx**, and **sqlalchemy** packages.   \n",
                "\n",
                "### **Steps**:\n",
                "1. Create a pipeline to train a LinearRegression model.\n",
                "2. Convert the model to the ONNX format. \n",
                "3. Test the ONNX model.\n",
                "4. Insert the ONNX model into SQL Server.\n",
                "\n",
                "### **Next Steps**:\n",
                "[Run native PREDICT in SQL Server using the ONNX model](Native%20PREDICT%20on%20Azure%20SQL%20Database%20Edge.ipynb). "
            ],
            "metadata": {
                "azdata_cell_guid": "eb24d4cb-0aa9-4a48-a301-930a93856914"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **1. Train a Pipeline**\n",
                "Split the dataset to use features to preduct the median value of a house. Create a pipeline to train the LinearRegression model and then calculate the R2 score and mean squared error."
            ],
            "metadata": {
                "azdata_cell_guid": "08fc39e1-7070-4ee0-a347-01dcc7eb5ed7"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\r\n",
                "import onnxmltools\r\n",
                "import onnxruntime as rt\r\n",
                "import pandas as pd\r\n",
                "import skl2onnx\r\n",
                "import sklearn\r\n",
                "import sklearn.datasets\r\n",
                "\r\n",
                "from sklearn.datasets import load_boston\r\n",
                "boston = load_boston()\r\n",
                "boston\r\n",
                "\r\n",
                "df = pd.DataFrame(data=np.c_[boston['data'], boston['target']], columns=boston['feature_names'].tolist() + ['MEDV'])\r\n",
                "\r\n",
                "# x contains all predictors (features)\r\n",
                "x = df.drop(['MEDV'], axis = 1)\r\n",
                "\r\n",
                "# y is what we are trying to predict - the median value\r\n",
                "y = df.iloc[:,-1]\r\n",
                "\r\n",
                "\r\n",
                " # Split the data frame into features and target\r\n",
                "x_train = df.drop(['MEDV'], axis = 1)\r\n",
                "y_train = df.iloc[:,-1]"
            ],
            "metadata": {
                "azdata_cell_guid": "028c8f33-00d6-4d69-aa83-6adcc1fbb3da"
            },
            "outputs": [],
            "execution_count": 1
        },
        {
            "cell_type": "code",
            "source": [
                "print(\"\\n*** Training data set x\\n\")\r\n",
                "print(x_train.head())\r\n",
                "\r\n",
                "print(\"\\n*** Training data set y\\n\")\r\n",
                "print(y_train.head())"
            ],
            "metadata": {
                "azdata_cell_guid": "a8c7cb08-063a-44a0-ae08-be85498c77c9"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\n*** Training data set x\n\n      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n\n   PTRATIO       B  LSTAT  \n0     15.3  396.90   4.98  \n1     17.8  396.90   9.14  \n2     17.8  392.83   4.03  \n3     18.7  394.63   2.94  \n4     18.7  396.90   5.33  \n\n*** Training data set y\n\n0    24.0\n1    21.6\n2    34.7\n3    33.4\n4    36.2\nName: MEDV, dtype: float64\n"
                }
            ],
            "execution_count": 2
        },
        {
            "cell_type": "code",
            "source": [
                "from sklearn.compose import ColumnTransformer\r\n",
                "from sklearn.linear_model import LinearRegression\r\n",
                "from sklearn.pipeline import Pipeline\r\n",
                "from sklearn.preprocessing import RobustScaler\r\n",
                "\r\n",
                "continuous_transformer = Pipeline(steps=[('scaler', RobustScaler())])\r\n",
                "\r\n",
                "# All columns are numeric - normalize them\r\n",
                "preprocessor = ColumnTransformer(\r\n",
                "    transformers=[\r\n",
                "        ('continuous', continuous_transformer, [i for i in range(len(x_train.columns))])])\r\n",
                "\r\n",
                "model = Pipeline(\r\n",
                "    steps=[\r\n",
                "        ('preprocessor', preprocessor),\r\n",
                "        ('regressor', LinearRegression())])\r\n",
                "\r\n",
                "# Train the model\r\n",
                "model.fit(x_train, y_train)"
            ],
            "metadata": {
                "azdata_cell_guid": "f8ab7482-f5cb-4ab1-9d04-7d71a1a8e3e1"
            },
            "outputs": [
                {
                    "output_type": "execute_result",
                    "execution_count": 3,
                    "data": {
                        "text/plain": "Pipeline(memory=None,\n         steps=[('preprocessor',\n                 ColumnTransformer(n_jobs=None, remainder='drop',\n                                   sparse_threshold=0.3,\n                                   transformer_weights=None,\n                                   transformers=[('continuous',\n                                                  Pipeline(memory=None,\n                                                           steps=[('scaler',\n                                                                   RobustScaler(copy=True,\n                                                                                quantile_range=(25.0,\n                                                                                                75.0),\n                                                                                with_centering=True,\n                                                                                with_scaling=True))],\n                                                           verbose=False),\n                                                  [0, 1, 2, 3, 4, 5, 6, 7, 8, 9,\n                                                   10, 11, 12])],\n                                   verbose=False)),\n                ('regressor',\n                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n                                  normalize=False))],\n         verbose=False)"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "y_pred = model.predict(x_train)"
            ],
            "metadata": {
                "azdata_cell_guid": "f04c6d19-3ab7-4f6d-802c-c66a770ac3b3"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "code",
            "source": [
                "# Score the model\n",
                "from sklearn.metrics import r2_score, mean_squared_error\n",
                "sklearn_r2_score = r2_score(y_train, y_pred)\n",
                "sklearn_mse = mean_squared_error(y_train, y_pred)\n",
                "print('*** Scikit-learn r2 score: {}'.format(sklearn_r2_score))\n",
                "print('*** Scikit-learn MSE: {}'.format(sklearn_mse))"
            ],
            "metadata": {
                "azdata_cell_guid": "610bd438-daa4-49be-a4c4-422fce4bef96"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "*** Scikit-learn r2 score: 0.7406426641094094\n*** Scikit-learn MSE: 21.894831181729206\n"
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **2. Convert the model to ONNX**\n",
                "Using skl2onnx, we will convert our LinearRegression model to the ONNX format and save it locally."
            ],
            "metadata": {
                "azdata_cell_guid": "4e02ff1e-bf63-45e3-aaf4-bd1da0fc3e04"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from skl2onnx.common.data_types import FloatTensorType, Int64TensorType, DoubleTensorType\r\n",
                "\r\n",
                "def convert_dataframe_schema(df, drop=None, batch_axis=False):\r\n",
                "    inputs = []\r\n",
                "    nrows = None if batch_axis else 1\r\n",
                "    for k, v in zip(df.columns, df.dtypes):\r\n",
                "        if drop is not None and k in drop:\r\n",
                "            continue\r\n",
                "        if v == 'int64':\r\n",
                "            t = Int64TensorType([nrows, 1])\r\n",
                "        elif v == 'float32':\r\n",
                "            t = FloatTensorType([nrows, 1])\r\n",
                "        elif v == 'float64':\r\n",
                "            t = DoubleTensorType([nrows, 1])\r\n",
                "        else:\r\n",
                "            raise Exception(\"Bad type\")\r\n",
                "        inputs.append((k, t))\r\n",
                "    return inputs"
            ],
            "metadata": {
                "azdata_cell_guid": "00e8bb63-66d0-4373-a605-b3fac050fad1"
            },
            "outputs": [],
            "execution_count": 7
        },
        {
            "cell_type": "code",
            "source": [
                "# Convert the scikit model to onnx format\n",
                "onnx_model = skl2onnx.convert_sklearn(model, 'Boston Data', convert_dataframe_schema(x_train))\n",
                "# Save the onnx model locally\n",
                "onnx_model_path = 'boston1.model.onnx'\n",
                "onnxmltools.utils.save_model(onnx_model, onnx_model_path)"
            ],
            "metadata": {
                "azdata_cell_guid": "511bb29e-ea93-4fa0-807c-fd399ca7edab"
            },
            "outputs": [],
            "execution_count": 8
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **3. Test the ONNX model**\n",
                "After converting the model to ONNX format, we score the model to show little to no degradation in performance.\n",
                "\n",
                "*ONNX Runtime uses floats instead of doubles which explains small potential discrepencies.*"
            ],
            "metadata": {
                "azdata_cell_guid": "caad1282-3dc2-44c3-ae12-13457c8f6a46"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import onnxruntime as rt\n",
                "sess = rt.InferenceSession(onnx_model_path)\n",
                "\n",
                "y_pred = np.full(shape=(len(x_train)), fill_value=np.nan)\n",
                "\n",
                "for i in range(len(x_train)):\n",
                "    inputs = {}\n",
                "    for j in range(len(x_train.columns)):\n",
                "        inputs[x_train.columns[j]] = np.full(shape=(1,1), fill_value=x_train.iloc[i,j])\n",
                "\n",
                "    sess_pred = sess.run(None, inputs)\n",
                "    y_pred[i] = sess_pred[0][0][0]\n",
                "\n",
                "onnx_r2_score = r2_score(y_train, y_pred)\n",
                "onnx_mse = mean_squared_error(y_train, y_pred)\n",
                "\n",
                "print()\n",
                "print('*** Onnx r2 score: {}'.format(onnx_r2_score))\n",
                "print('*** Onnx MSE: {}\\n'.format(onnx_mse))\n",
                "print('R2 Scores are equal' if sklearn_r2_score == onnx_r2_score else 'Difference in R2 scores: {}'.format(abs(sklearn_r2_score - onnx_r2_score)))\n",
                "print('MSE are equal' if sklearn_mse == onnx_mse else 'Difference in MSE scores: {}'.format(abs(sklearn_mse - onnx_mse)))\n",
                "print()\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "98dea52e-7b56-4a07-9a42-3f3d81c2c7ae"
            },
            "outputs": [
                {
                    "output_type": "stream",
                    "name": "stdout",
                    "text": "\n*** Onnx r2 score: 0.7406426691136831\n*** Onnx MSE: 21.894830759270633\n\nDifference in R2 scores: 5.00427377314594e-09\nDifference in MSE scores: 4.224585730128183e-07\n\n"
                }
            ],
            "execution_count": 9
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **4. Insert the ONNX model into SQL Server**\n",
                "Now, we will store the model in SQL Server. We will create a database ```onnx``` with a ```models``` table to store the ONNX model. You will be prompted to enter your **server address, username, and password**. You will need to also import the *pyodbc* package."
            ],
            "metadata": {
                "azdata_cell_guid": "48bc6127-0e1e-4855-b5c8-c79e607cc670"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import pyodbc\r\n",
                "import getpass\r\n",
                "\r\n",
                "server = input(\"Enter the server address:\")\r\n",
                "username = input(\"Enter username:\")\r\n",
                "password = getpass.getpass(prompt=\"Enter password:\")\r\n",
                "\r\n",
                "# Connect to the master DB to create the new onnx database\r\n",
                "connection_string = \"Driver={ODBC Driver 17 for SQL Server};Server=\" + server + \";Database=master;UID=\" + username + \";PWD=\" + password + \";\"\r\n",
                "\r\n",
                "conn = pyodbc.connect(connection_string, autocommit=True)\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "database = 'onnx'\r\n",
                "query = 'DROP DATABASE IF EXISTS ' + database\r\n",
                "cursor.execute(query)\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Create onnx database\r\n",
                "query = 'CREATE DATABASE ' + database\r\n",
                "cursor.execute(query)\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Connect to onnx database\r\n",
                "\r\n",
                "db_connection_string = \"Driver={ODBC Driver 17 for SQL Server};Server=\" + server + \";Database=\" + database + \";UID=\" + username + \";PWD=\" + password + \";\"\r\n",
                "\r\n",
                "conn = pyodbc.connect(db_connection_string, autocommit=True)\r\n",
                "cursor = conn.cursor()\r\n",
                "\r\n",
                "table_name = 'models'\r\n",
                "\r\n",
                "# Drop the table if it exists\r\n",
                "query = f'drop table if exists {table_name}'\r\n",
                "cursor.execute(query)\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Create the model table\r\n",
                "query = f'create table {table_name} ( ' \\\r\n",
                "    f'[id] [int] IDENTITY(1,1) NOT NULL, ' \\\r\n",
                "    f'[data] [varbinary](max) NULL, ' \\\r\n",
                "    f'[description] varchar(1000))'\r\n",
                "cursor.execute(query)\r\n",
                "conn.commit()\r\n",
                "\r\n",
                "# Insert the ONNX model into the models table\r\n",
                "query = f\"insert into {table_name} ([description], [data]) values ('Onnx Model',?)\"\r\n",
                "\r\n",
                "model_bits = onnx_model.SerializeToString()\r\n",
                "\r\n",
                "insert_params  = (pyodbc.Binary(model_bits))\r\n",
                "cursor.execute(query, insert_params)\r\n",
                "conn.commit()\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "0588ddb3-fd3e-4e3f-8b06-c14b6d6db2ed"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Load the data into SQL Server**\n",
                "\n",
                "We will create two tables, **features** and **target**, to store subsets of the boston housing dataset. \n",
                "* Features will contain all data being used to predict the target, median value. \n",
                "* Target contains the median value for each record in the dataset. \n",
                "\n",
                "You will need to import the *sqlalchemy* package."
            ],
            "metadata": {
                "azdata_cell_guid": "626e6c25-a915-4311-a66f-29ac628edbc9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "    import sqlalchemy\r\n",
                "    from sqlalchemy import create_engine\r\n",
                "    import urllib\r\n",
                "\r\n",
                "    db_connection_string = \"Driver={ODBC Driver 17 for SQL Server};Server=\" + server + \";Database=\" + database + \";UID=\" + username + \";PWD=\" + password + \";\"\r\n",
                "\r\n",
                "    conn = pyodbc.connect(db_connection_string)\r\n",
                "    cursor = conn.cursor()\r\n",
                "\r\n",
                "    features_table_name = 'features'\r\n",
                "\r\n",
                "    # Drop the table if it exists\r\n",
                "    query = f'drop table if exists {features_table_name}'\r\n",
                "    cursor.execute(query)\r\n",
                "    conn.commit()\r\n",
                "\r\n",
                "    # Create the features table\r\n",
                "    query = \\\r\n",
                "        f'create table {features_table_name} ( ' \\\r\n",
                "        f'    [CRIM] float, ' \\\r\n",
                "        f'    [ZN] float, ' \\\r\n",
                "        f'    [INDUS] float, ' \\\r\n",
                "        f'    [CHAS] float, ' \\\r\n",
                "        f'    [NOX] float, ' \\\r\n",
                "        f'    [RM] float, ' \\\r\n",
                "        f'    [AGE] float, ' \\\r\n",
                "        f'    [DIS] float, ' \\\r\n",
                "        f'    [RAD] float, ' \\\r\n",
                "        f'    [TAX] float, ' \\\r\n",
                "        f'    [PTRATIO] float, ' \\\r\n",
                "        f'    [B] float, ' \\\r\n",
                "        f'    [LSTAT] float, ' \\\r\n",
                "        f'    [id] int)'\r\n",
                "\r\n",
                "    cursor.execute(query)\r\n",
                "    conn.commit()\r\n",
                "\r\n",
                "    target_table_name = 'target'\r\n",
                "\r\n",
                "    # Create the target table\r\n",
                "    query = \\\r\n",
                "        f'create table {target_table_name} ( ' \\\r\n",
                "        f'    [MEDV] float, ' \\\r\n",
                "        f'    [id] int)'\r\n",
                "\r\n",
                "    x_train['id'] = range(1, len(x_train)+1)\r\n",
                "    y_train['id'] = range(1, len(y_train)+1)\r\n",
                "\r\n",
                "    print(x_train.head())\r\n",
                "    print(y_train.head())"
            ],
            "metadata": {
                "azdata_cell_guid": "bc3c4b55-5f65-4aab-8d05-566be0137e2f"
            },
            "outputs": [],
            "execution_count": 5
        },
        {
            "cell_type": "markdown",
            "source": [
                "Finally, using sqlalchemy, we insert the `x_train` and `y_train` pandas dataframes into tables `features` and `target`, respectively. "
            ],
            "metadata": {
                "azdata_cell_guid": "bb6f4278-13c1-4673-bc00-74b41b08de66"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "db_connection_string = 'mssql+pyodbc://' + username + ':' + password + '@' + server + '/' + database + '?driver=ODBC+Driver+17+for+SQL+Server'\r\n",
                "sql_engine = sqlalchemy.create_engine(db_connection_string)\r\n",
                "x_train.to_sql(features_table_name, sql_engine, if_exists='append', index=False)\r\n",
                "y_train.to_sql(target_table_name, sql_engine, if_exists='append', index=False)"
            ],
            "metadata": {
                "azdata_cell_guid": "5dd6a118-9f47-4e30-9f90-5a4dd5568171"
            },
            "outputs": [],
            "execution_count": 22
        },
        {
            "cell_type": "markdown",
            "source": [
                "You will now be able to view the data in SQL Server."
            ],
            "metadata": {
                "azdata_cell_guid": "7aa87c74-a224-4b8a-8caa-cef828468a3c"
            }
        }
    ]
}