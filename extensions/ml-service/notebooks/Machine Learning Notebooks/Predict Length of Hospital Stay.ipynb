{
    "metadata": {
        "kernelspec": {
            "name": "SQL",
            "display_name": "SQL",
            "language": "sql"
        },
        "language_info": {
            "name": "sql",
            "version": ""
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<p align=\"center\">\n",
                "<img src =\"https://raw.githubusercontent.com/microsoft/azuredatastudio/master/src/sql/media/microsoft_logo_gray.svg?sanitize=true\" width=\"250\" align=\"center\">\n",
                "</p>\n",
                "\n",
                "# **Predict Length of Hospital Stay**\n",
                "In this notebook, we will go through the process of loading data into a <a href=\"https://docs.microsoft.com/sql/big-data-cluster/big-data-cluster-overview?view=sqlallproducts-allversions\">SQL Server 2019 Big Data Cluster</a> and then train machine learning models on the data.\n",
                "Follow the **Prerequisites** section below before starting the rest of the notebook.\n",
                "Once you have a Big Data Cluster set up, continue to the next steps:\n",
                "1. Prepare Data\n",
                "2. Define Training Features\n",
                "3. Train a Random Forest and a Neural Network (MLP) model\n",
                "4. Store Models in SQL Server and then run Native Predict\n",
                "\n",
                "<!-- <span style=\"color:red\"><font size=\"3\">Please press the \"Run Cells\" button to run the notebook</font></span> -->"
            ],
            "metadata": {
                "azdata_cell_guid": "b8807529-b58e-46c6-94a9-5db34f2d822f"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Prerequisites**\n",
                "* Connect to a SQL Server 2019 Big Data Cluster. <a href=\"https://docs.microsoft.com/en-us/sql/big-data-cluster/deploy-get-started?view=sqlallproducts-allversions\">Get Started with SQL Server Big Data Cluster</a> to deploy and connect to a Big Data Cluster.\n",
                "* Upload the hospital length of stay dataset into HDFS at `user/LengthOfStay.csv`.\n",
                "* Create or select a database to use for this notebook."
            ],
            "metadata": {
                "azdata_cell_guid": "14b99abc-8e2a-419d-8569-b6b953fb3855"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **1. Prepare Data**\n",
                "In this section, we will:\n",
                "* Create an External Data Source and Table to our data in HDFS.\n",
                "* Split the data into train/test sets."
            ],
            "metadata": {
                "azdata_cell_guid": "8b4b25ab-793f-4e4b-b993-2cc5ca86de4c"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create an external data source in your **target** database."
            ],
            "metadata": {
                "azdata_cell_guid": "0ac5b130-298b-494b-992d-00eceb42fe42"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "IF NOT EXISTS(SELECT * FROM sys.external_data_sources WHERE name = 'SqlStoragePool')\r\n",
                "BEGIN\r\n",
                "  CREATE EXTERNAL DATA SOURCE SqlStoragePool\r\n",
                "  WITH (LOCATION = 'sqlhdfs://controller-svc/default');\r\n",
                "END"
            ],
            "metadata": {
                "azdata_cell_guid": "ab790297-703c-4106-923c-d4cbd8be22aa"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create an External File Format that will be used to parse the LengthOfStay.csv."
            ],
            "metadata": {
                "azdata_cell_guid": "24ce61ca-055d-425a-a6e6-1166a753b842"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "CREATE EXTERNAL FILE FORMAT [FileFormat_dbo_patients-data]\r\n",
                "            WITH (FORMAT_TYPE = DELIMITEDTEXT, FORMAT_OPTIONS (FIELD_TERMINATOR = ',', STRING_DELIMITER = '\"', FIRST_ROW = 2));"
            ],
            "metadata": {
                "azdata_cell_guid": "427452b9-9138-4884-99ee-ed4089e268c8"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "markdown",
            "source": [
                "Create an external table, dbo.patients, for the LengthOfStay data in HDFS."
            ],
            "metadata": {
                "azdata_cell_guid": "4405f707-66c2-4650-acdb-6e8338166264"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "CREATE EXTERNAL TABLE [dbo].[patients](\r\n",
                "\teid int NOT NULL,\r\n",
                "\tvdate date NOT NULL,\r\n",
                "\trcount varchar(2) NOT NULL,\r\n",
                "\tgender char(1) NOT NULL,\r\n",
                "\tdialysisrenalendstage int NOT NULL,\r\n",
                "\tasthma int NOT NULL,\r\n",
                "\tirondef int NOT NULL,\r\n",
                "\tpneum int NOT NULL,\r\n",
                "\tsubstancedependence int NOT NULL,\r\n",
                "\tpsychologicaldisordermajor int NOT NULL,\r\n",
                "\tdepress int NOT NULL,\r\n",
                "\tpsychother int NOT NULL,\r\n",
                "\tfibrosisandother int NOT NULL,\r\n",
                "\tmalnutrition int NOT NULL,\r\n",
                "\themo int NOT NULL,\r\n",
                "\thematocrit float NOT NULL,\r\n",
                "\tneutrophils float NOT NULL,\r\n",
                "\tsodium float NOT NULL,\r\n",
                "\tglucose float NOT NULL,\r\n",
                "\tbloodureanitro float NOT NULL,\r\n",
                "\tcreatinine float NOT NULL,\r\n",
                "\tbmi float NOT NULL,\r\n",
                "\tpulse float NOT NULL,\r\n",
                "\trespiration float NOT NULL,\r\n",
                "\tsecondarydiagnosisnonicd9 int NOT NULL,\r\n",
                "\tdischarged date NOT NULL,\r\n",
                "\tfacid char(1) NOT NULL,\r\n",
                "\tlengthofstay int NOT NULL\r\n",
                ")\r\n",
                "WITH (LOCATION = N'/user/LengthOfStay.csv', DATA_SOURCE = [SqlStoragePool], FILE_FORMAT = [FileFormat_dbo_patients-data]);"
            ],
            "metadata": {
                "azdata_cell_guid": "eba57ebe-dbea-4a2a-9f81-f440e9577e17"
            },
            "outputs": [
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Commands completed successfully."
                    },
                    "metadata": {}
                },
                {
                    "output_type": "display_data",
                    "data": {
                        "text/html": "Total execution time: 00:00:00.153"
                    },
                    "metadata": {}
                }
            ],
            "execution_count": 6
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Split Data into Train/Test sets**"
            ],
            "metadata": {
                "azdata_cell_guid": "d55cf9ae-92c5-404c-bea7-395ff60ac28b"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "CREATE TABLE dbo.Train_Id(\r\n",
                "\teid int NOT NULL,\r\n",
                "\tINDEX cci_train_ids CLUSTERED COLUMNSTORE\r\n",
                ");\r\n",
                "GO\r\n",
                "\r\n",
                "DECLARE @train_percent int = 70;\r\n",
                "TRUNCATE TABLE Train_Id;\r\n",
                "INSERT INTO Train_Id (eid)\r\n",
                "SELECT eid\r\n",
                "FROM dbo.patients\r\n",
                "WHERE ABS(CAST(BINARY_CHECKSUM(eid, NEWID()) as int)) % 100 < @train_percent;\r\n",
                "GO\r\n",
                "\r\n",
                "-- Training set\r\n",
                "SELECT  (hematocrit - AVG(hematocrit) OVER())/STDEV(hematocrit) OVER()  as hematocrit,\r\n",
                "\t\t(neutrophils - AVG(neutrophils) OVER())/STDEV(neutrophils) OVER() as neutrophils,\r\n",
                "\t\t(sodium - AVG(sodium) OVER())/STDEV(sodium) OVER() as sodium,\r\n",
                "\t\t(glucose - AVG(glucose) OVER())/STDEV(glucose) OVER()  as glucose,\r\n",
                "\t\t(bloodureanitro - AVG(bloodureanitro) OVER())/STDEV(bloodureanitro) OVER() as bloodureanitro,\r\n",
                "\t\t(creatinine - AVG(creatinine) OVER())/STDEV(creatinine) OVER() as creatinine,\r\n",
                "\t\t(bmi - AVG(bmi) OVER())/STDEV(bmi) OVER() as bmi,\r\n",
                "\t\t(pulse - AVG(pulse) OVER())/STDEV(pulse) OVER() as pulse,\r\n",
                "\t\t(respiration - AVG(respiration) OVER())/STDEV(respiration) OVER() as respiration,\r\n",
                "\t\tCAST(hemo as int) + CAST(dialysisrenalendstage as int) + CAST(asthma as int) + CAST(irondef as int) + CAST(pneum as int) +\r\n",
                "\t\t\tCAST(substancedependence as int) + CAST(psychologicaldisordermajor as int) + CAST(depress as int) +\r\n",
                "            CAST(psychother as int) + CAST(fibrosisandother as int) + CAST(malnutrition as int) AS number_of_issues,\r\n",
                "\t\tasthma, \r\n",
                "\t\tdepress, \r\n",
                "\t\tdialysisrenalendstage, \r\n",
                "\t\tfibrosisandother, \r\n",
                "\t\t(case when gender = 'M' then 1 else 0 end) as gender, \r\n",
                "\t\themo, \r\n",
                "\t\tirondef, \r\n",
                "\t\tmalnutrition, \r\n",
                "\t\tpneum, \r\n",
                "\t\tpsychologicaldisordermajor, \r\n",
                "\t\tpsychother,\r\n",
                "\t\tsecondarydiagnosisnonicd9, \r\n",
                "\t\tsubstancedependence, \r\n",
                "\t\t(case when rcount = '5+' then 5 else rcount end) as rcount, \r\n",
                "\t\tlengthofstay\r\n",
                "INTO dbo.patients_train\r\n",
                "FROM dbo.patients as l\r\n",
                "WHERE EXISTS(SELECT * FROM Train_Id as t WHERE t.eid = l.eid);\r\n",
                "GO\r\n",
                "\r\n",
                "SELECT  (hematocrit - AVG(hematocrit) OVER())/STDEV(hematocrit) OVER() as hematocrit,\r\n",
                "\t\t(neutrophils - AVG(neutrophils) OVER())/STDEV(neutrophils) OVER() as neutrophils,\r\n",
                "\t\t(sodium - AVG(sodium) OVER())/STDEV(sodium) OVER() as sodium,\r\n",
                "\t\t(glucose - AVG(glucose) OVER())/STDEV(glucose) OVER()  as glucose,\r\n",
                "\t\t(bloodureanitro - AVG(bloodureanitro) OVER())/STDEV(bloodureanitro) OVER() as bloodureanitro,\r\n",
                "\t\t(creatinine - AVG(creatinine) OVER())/STDEV(creatinine) OVER() as creatinine,\r\n",
                "\t\t(bmi - AVG(bmi) OVER())/STDEV(bmi) OVER() as bmi,\r\n",
                "\t\t(pulse - AVG(pulse) OVER())/STDEV(pulse) OVER() as pulse,\r\n",
                "\t\t(respiration - AVG(respiration) OVER())/STDEV(respiration) OVER() as respiration,\r\n",
                "\t\tCAST(hemo as int) + CAST(dialysisrenalendstage as int) + CAST(asthma as int) + CAST(irondef as int) + CAST(pneum as int) +\r\n",
                "\t\t\tCAST(substancedependence as int) + CAST(psychologicaldisordermajor as int) + CAST(depress as int) +\r\n",
                "            CAST(psychother as int) + CAST(fibrosisandother as int) + CAST(malnutrition as int) AS number_of_issues,\r\n",
                "\t\tasthma, \r\n",
                "\t\tdepress, \r\n",
                "\t\tdialysisrenalendstage, \r\n",
                "\t\tfibrosisandother, \r\n",
                "\t\t(case when gender = 'M' then 1 else 0 end) as gender, \r\n",
                "\t\themo, \r\n",
                "\t\tirondef,\r\n",
                "\t\tmalnutrition, \r\n",
                "\t\tpneum, \r\n",
                "\t\tpsychologicaldisordermajor, \r\n",
                "\t\tpsychother,\r\n",
                "\t\tsecondarydiagnosisnonicd9, \r\n",
                "\t\tsubstancedependence, \r\n",
                "\t\t(case when rcount = '5+' then 5 else rcount end) as rcount, \r\n",
                "\t\tlengthofstay\r\n",
                "INTO dbo.patients_score\r\n",
                "FROM dbo.patients  as l\r\n",
                "WHERE NOT EXISTS(SELECT * FROM Train_Id as t WHERE t.eid = l.eid);\r\n",
                "GO\r\n",
                "\r\n",
                "SELECT TOP(30)\r\n",
                "CAST([hematocrit] AS REAL) AS [hematocrit],\r\n",
                "CAST([neutrophils] AS REAL) AS [neutrophils],\r\n",
                "CAST([sodium] AS REAL) AS [sodium],\r\n",
                "CAST([glucose] AS REAL) AS [glucose],\r\n",
                "CAST([bloodureanitro] AS REAL) AS [bloodureanitro],\r\n",
                "CAST([creatinine] AS REAL) AS [creatinine],\r\n",
                "CAST([bmi] AS REAL) AS [bmi],\r\n",
                "CAST([pulse] AS REAL) AS [pulse],\r\n",
                "CAST([respiration] AS REAL) AS [respiration],\r\n",
                "CAST([number_of_issues] AS BIGINT) AS [number_of_issues],\r\n",
                "CAST([asthma] AS BIGINT) AS [asthma],\r\n",
                "CAST([depress] AS BIGINT) AS [depress],\r\n",
                "CAST([dialysisrenalendstage] AS BIGINT) AS [dialysisrenalendstage],\r\n",
                "CAST([fibrosisandother] AS BIGINT) AS [fibrosisandother],\r\n",
                "CAST([gender] AS BIGINT) AS [gender],\r\n",
                "CAST([hemo] AS BIGINT) AS [hemo],\r\n",
                "CAST([irondef] AS BIGINT) AS [irondef],\r\n",
                "CAST([malnutrition] AS BIGINT) AS [malnutrition],\r\n",
                "CAST([pneum] AS BIGINT) AS [pneum],\r\n",
                "CAST([psychologicaldisordermajor] AS BIGINT) AS [psychologicaldisordermajor],\r\n",
                "CAST([psychother] AS BIGINT) AS [psychother],\r\n",
                "CAST([secondarydiagnosisnonicd9] AS BIGINT) AS [secondarydiagnosisnonicd9],\r\n",
                "CAST([substancedependence] AS BIGINT) AS [substancedependence],\r\n",
                "CAST([rcount] AS BIGINT) AS [rcount]\r\n",
                "INTO dbo.patients_score_cooked\r\n",
                "FROM dbo.patients_score\r\n",
                "GO"
            ],
            "metadata": {
                "azdata_cell_guid": "60fb9c3c-c598-4ff6-bd7c-ea2025e69a1d"
            },
            "outputs": [],
            "execution_count": 12
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Change Kernel from SQL to Python 3**"
            ],
            "metadata": {
                "azdata_cell_guid": "0ed0d915-1496-489d-8110-e71f988169ad"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **2. Define Training Features**"
            ],
            "metadata": {
                "azdata_cell_guid": "f082da88-f362-46fe-a0b6-e042e293f40a"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Import Libraries**"
            ],
            "metadata": {
                "azdata_cell_guid": "6bbf7c01-95d4-407b-be5a-9dc07e97ba24"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import numpy as np\n",
                "import pandas as pd\n",
                "import pyodbc\n",
                "import pickleimport pickle\n",
                "\n",
                "from sklearn import preprocessing\n",
                "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, RobustScaler\n",
                "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
                "from sklearn.pipeline import make_pipeline\n",
                "from sklearn.linear_model import LogisticRegression\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "from sklearn.pipeline import Pipeline\n",
                "from sklearn.neural_network import MLPClassifier\n",
                "from sklearn.metrics import accuracy_score"
            ],
            "metadata": {
                "azdata_cell_guid": "e87ba49d-ad34-4549-a3e9-0d690bf811ea"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Define Training Features**"
            ],
            "metadata": {
                "azdata_cell_guid": "f01ec552-2cc1-41ef-b2a2-e0fc621c6cf6"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "patient_columns = ['hematocrit', 'neutrophils','sodium', 'glucose', 'bloodureanitro', 'creatinine', 'bmi', \n",
                "                   'pulse', 'respiration', 'number_of_issues', 'asthma', 'depress', 'dialysisrenalendstage', \n",
                "                   'fibrosisandother', 'gender', 'hemo', 'irondef', 'malnutrition', 'pneum', 'psychologicaldisordermajor', \n",
                "                   'psychother', 'secondarydiagnosisnonicd9', 'substancedependence', 'rcount', 'lengthofstay']\n",
                "\n",
                "continuous_features  = ['hematocrit', 'neutrophils','sodium', 'glucose', 'bloodureanitro', 'creatinine', 'bmi'\n",
                "                        , 'pulse', 'respiration']\n",
                "\n",
                "categorical_features = ['number_of_issues', 'asthma', 'depress', 'dialysisrenalendstage', 'fibrosisandother', 'gender', \n",
                "                        'hemo', 'irondef', 'malnutrition', 'pneum', 'psychologicaldisordermajor', 'psychother', \n",
                "                        'secondarydiagnosisnonicd9', 'substancedependence', 'rcount']\n",
                "\n",
                "sql_conn = pyodbc.connect('DRIVER={SQL Server Native Client 11.0}; SERVER=localhost; DATABASE=sonnx; Uid=sa; Pwd=Cisl_2014;')\n",
                "\n",
                "data_query = \"SELECT [hematocrit],[neutrophils],[sodium],[glucose],[bloodureanitro],[creatinine],[bmi],[pulse], \\\n",
                "                     [respiration],[number_of_issues],[asthma],[depress],[dialysisrenalendstage],[fibrosisandother], \\\n",
                "                     [gender],[hemo],[irondef],[malnutrition],[pneum],[psychologicaldisordermajor],[psychother], \\\n",
                "                     [secondarydiagnosisnonicd9],[substancedependence],[rcount],[lengthofstay] \\\n",
                "              FROM [dbo].[patients_train]\"\n",
                "\n",
                "def load_data_from_sqlserver(sql_conn):\n",
                "    data = pd.read_sql(data_query, sql_conn)\n",
                "    #data = pd.read_csv(path, header=0, names=patient_columns)\n",
                "    data = data[continuous_features + categorical_features + ['lengthofstay']]\n",
                "    # print(data['lengthofstay'].tail())\n",
                "    data_y = data['lengthofstay'];\n",
                "    data_x = data.loc[:, data.columns != 'lengthofstay'];\n",
                "    return data_x, data_y\n",
                "\n",
                "def convert_dataframe_schema(df, drop=None):\n",
                "    inputs = []\n",
                "    for k, v in zip(df.columns, df.dtypes):\n",
                "        # print(df.columns);\n",
                "        # print(df.dtypes);\n",
                "        if drop is not None and k in drop:\n",
                "            continue\n",
                "        if v == 'int64':\n",
                "            t = Int64TensorType([1, 1])\n",
                "        elif v == 'float64':\n",
                "            t = FloatTensorType([1, 1])\n",
                "        else:\n",
                "            t = StringTensorType([1, 1])\n",
                "        inputs.append((k, t))\n",
                "    return inputs\n",
                "\n",
                "continuous_transformer = Pipeline(steps=[('scaler', RobustScaler())])\n",
                "categorical_transformer = Pipeline(steps=[('onehot', OneHotEncoder(sparse=False))])\n",
                "\n",
                "preprocessor = ColumnTransformer(\n",
                "     transformers=[\n",
                "         ('continuous', continuous_transformer, [0, 1, 2, 3, 4, 5, 6, 7, 8]),\n",
                "         ('categorical', categorical_transformer, [9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23])\n",
                "     ])"
            ],
            "metadata": {
                "azdata_cell_guid": "359db6ee-913a-480d-9541-fcd99009bf0b"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **3. Train Random Forest and Neural Network model**\n",
                "In this section, we will train two models: Random Forest and a Neural Network (Multi-Layer Perceptron).\n",
                "As defined earlier, these models are trained using a 70/30 train/test split.\n",
                "\n",
                "We will then save them to a pickle file to later be stored into SQL Server.\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "5da6fee0-f3ce-42a3-8e4e-0f00b843d1c6"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Random Forest** "
            ],
            "metadata": {
                "azdata_cell_guid": "fce8208d-6947-4d3a-a985-a707b673a32b"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def train_patients_rf():\n",
                "    train_x, train_y = load_data_from_sqlserver(sql_conn)\n",
                "    \n",
                "    model = Pipeline(\n",
                "        steps=[\n",
                "            ('preprocessor', preprocessor),\n",
                "            ('classifier', RandomForestClassifier(max_depth = 4))])\n",
                "\n",
                "    model.fit(train_x, train_y)\n",
                "    return model\n",
                "\n",
                "trained_rf_model = train_patients_rf()"
            ],
            "metadata": {
                "azdata_cell_guid": "9ebdedb7-3af8-4ddb-9626-b885ae35b053"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Neural Network (Multi-Layer Perceptron)**"
            ],
            "metadata": {
                "azdata_cell_guid": "7aeb01b1-0d1d-4b18-8f6e-fc52fbe9d914"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "def train_patients_mlp():\n",
                "    train_x, train_y = load_data_from_sqlserver(sql_conn)\n",
                "    \n",
                "    model = Pipeline(\n",
                "        steps=[\n",
                "            ('preprocessor', preprocessor),\n",
                "            ('classifier', MLPClassifier(hidden_layer_sizes=(10, 10, 10), max_iter=100))])\n",
                "\n",
                "    model.fit(train_x, train_y)\n",
                "    return model\n",
                "\n",
                "trained_mlp_model = train_patients_mlp()\n",
                "\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "ca6bfa23-77cb-4872-ba01-9652f6342c6e"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Serialize models using Pickle**\n",
                "In the cell below, define a filename for each model you want to save. Later, you will access this file to retrieve the models."
            ],
            "metadata": {
                "azdata_cell_guid": "eca6a2f8-75f1-4505-af2f-94342495cef1"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "filehandler_rf = open('', 'w') # create .pkl file in directory\n",
                "pickle.dump(trained_rf_model, filehandler_rf)\n",
                "\n",
                "filehandler_mlp = open('', 'w') # create .pkl file in directory\n",
                "pickle.dump(trained_mlp_model, filehandler_mlp)"
            ],
            "metadata": {
                "azdata_cell_guid": "bb704dae-bae4-4c09-84f8-cfea41f9c6fc"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **Switch to SQL Kernel**"
            ],
            "metadata": {
                "azdata_cell_guid": "91a0ec02-2cde-4b9d-870d-e63394dbb08c"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "## **4. Store Models in SQL Server and then run Native Predict**"
            ],
            "metadata": {
                "azdata_cell_guid": "c23b5653-da2f-4da4-8fdb-206d92c319ba"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Create table and then store the model in the table**\n",
                "You will have to insert the path to the model files you created above."
            ],
            "metadata": {
                "azdata_cell_guid": "c7de61ad-bdd8-4136-9ca8-9c8f33f7077d"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "DROP TABLE IF EXISTS dbo.hospital_stay_models;\n",
                "GO\n",
                "CREATE TABLE [dbo].[hospital_stay_models](\n",
                "\t[Id] [int] IDENTITY(1,1) NOT NULL,\n",
                "\t[Data] [varbinary](max) NULL,\n",
                "\t[Description] [varchar](200) NULL\n",
                ") ON [PRIMARY] TEXTIMAGE_ON [PRIMARY]\n",
                "GO"
            ],
            "metadata": {
                "azdata_cell_guid": "8deb8b2c-a8cf-4aaa-872f-0547c31f0701"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "INSERT INTO hospital_stay_models (Data, Description) \n",
                "\tSELECT BulkColumn, 'Random Forest model' FROM OPENROWSET (BULK '', SINGLE_BLOB) AS X -- Insert path to rf model file\n",
                "\n",
                "INSERT INTO hospital_stay_models (Data, Description) \n",
                "\tSELECT BulkColumn, 'MLP model' FROM OPENROWSET (BULK '', SINGLE_BLOB) AS X -- Insert path to mlp model file\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "6243bdc5-ea72-493a-8087-bf0cc34b8e96"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Native Predict Using Stored Models**"
            ],
            "metadata": {
                "azdata_cell_guid": "b0827a96-5bb2-4d81-b644-4d0855bc07a9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "DECLARE @model varbinary(max) = (SELECT Data from hospital_stay_models where id = 1)\n",
                "SELECT p.output_label AS 'length of stay'\n",
                "FROM PREDICT(model=@model, data=[patients_score_cooked]) with(output_label bigint) AS p"
            ],
            "metadata": {
                "azdata_cell_guid": "363265d1-224f-4c30-a1a3-f07385c6736f"
            },
            "outputs": [],
            "execution_count": 0
        },
        {
            "cell_type": "code",
            "source": [
                "DECLARE @model varbinary(max) = (SELECT Data FROM hospital_stay_models WHERE id = 2)\n",
                "SELECT p.output_label AS 'length of stay', patients_score_cooked.*\n",
                "FROM PREDICT(model=@model, data=patients_score_cooked) with(output_label bigint) AS p"
            ],
            "metadata": {
                "azdata_cell_guid": "a8132e6b-5607-4dbd-8eff-273128f03d41"
            },
            "outputs": [],
            "execution_count": 0
        }
    ]
}