{
    "metadata": {
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "language_info": {
            "name": "python",
            "version": "3.6.6",
            "mimetype": "text/x-python",
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "pygments_lexer": "ipython3",
            "nbconvert_exporter": "python",
            "file_extension": ".py"
        }
    },
    "nbformat_minor": 2,
    "nbformat": 4,
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "<p align=\"center\">\n",
                "<img src =\"https://raw.githubusercontent.com/microsoft/azuredatastudio/master/src/sql/media/microsoft_logo_gray.svg?sanitize=true\" width=\"250\" align=\"center\">\n",
                "</p>\n",
                " \n",
                "## Model Management with MLFlow on SQL Server 2019 Big Data Cluster in Azure Kubernetes Service\n",
                " \n",
                "This notebook walks through the process of deploying MLFlow in SQL Server 2019 Big Data Cluster in Azure Kubernetes Service. You will be able to connect to the container and track models using MLFlow after this.\n",
                " \n",
                "* Follow the instructions in the **Prerequisites** cell to install the tools if not already installed.\n",
                "* The **Required information** will check and prompt you for password if it is not set in the environment variable. The password will be used to access the cluster controller, SQL Server, and Knox.\n",
                "\n",
                "<span style=\"color:red\"><font size=\"3\">Please press the \"Run Cells\" button to run the notebook</font></span>"
            ],
            "metadata": {
                "azdata_cell_guid": "4f6bc3bc-3592-420a-b534-384011189005"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Prerequisites**\n",
                "Ensure the following tools are installed and added to PATH before proceeding.\n",
                "\n",
                "|Tools|Description|Installation|\n",
                "|---|---|---|\n",
                "|kubectl | Command-line tool for monitoring the underlying Kuberentes cluster | [Installation](https://kubernetes.io/docs/tasks/tools/install-kubectl/#install-kubectl-binary-using-native-package-management) |"
            ],
            "metadata": {
                "azdata_cell_guid": "d949980e-ad3f-4d02-ae84-7e4fbb19a087"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Check dependencies**"
            ],
            "metadata": {
                "azdata_cell_guid": "a56d3413-a730-4997-b5c2-c8abd972757e"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "import pandas,sys,os,json,time,subprocess\r\n",
                "pandas_version = pandas.__version__.split('.')\r\n",
                "pandas_major = int(pandas_version[0])\r\n",
                "pandas_minor = int(pandas_version[1])\r\n",
                "pandas_patch = int(pandas_version[2])\r\n",
                "if not (pandas_major > 0 or (pandas_major == 0 and pandas_minor > 24) or (pandas_major == 0 and pandas_minor == 24 and pandas_patch >= 2)):\r\n",
                "    sys.exit('Please upgrade the Notebook dependency before you can proceed, you can do it by running the \"Reinstall Notebook dependencies\" command in command palette (View menu -> Command Paletteâ€¦).')\r\n",
                "def run_command(command):\r\n",
                "    print(\"Executing: \" + command)\r\n",
                "    stdout = subprocess.check_output(\r\n",
                "        command,\r\n",
                "        stderr=subprocess.STDOUT,\r\n",
                "        shell=True).decode(\"utf-8\")\r\n",
                "    print(stdout)\r\n",
                "    return stdout\r\n",
                "    if _exit_code != 0:\r\n",
                "        sys.exit(f'Command execution failed with exit code: {str(_exit_code)}.\\n\\t{command}\\n')\r\n",
                "    print(f'Successfully executed: {command}')\r\n",
                "    \r\n",
                "run_command('kubectl version --client=true')"
            ],
            "metadata": {
                "azdata_cell_guid": "326645cf-022a-47f2-8aff-37de71da8955"
            },
            "outputs": [],
            "execution_count": 2
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Setup cluster context**\r\n",
                "Enter your kube_config and your Big Data Cluster name."
            ],
            "metadata": {
                "azdata_cell_guid": "4b859f5c-05c4-491e-a5a8-affa85baf0a4"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "from sys import platform\r\n",
                "\r\n",
                "home_dir = None\r\n",
                "if platform == \"linux\" or platform == \"linux2\":\r\n",
                "    home_dir = os.environ.get(\"HOME\")\r\n",
                "elif platform == \"darwin\":\r\n",
                "    home_dir = os.environ.get(\"HOME\")\r\n",
                "elif platform == \"win32\":\r\n",
                "    home_dir = os.environ.get(\"USERPROFILE\")\r\n",
                "default_config_path = os.path.join(home_dir, \".kube\", \"config\")\r\n",
                "kube_config = os.environ.get(\"KUBECONFIG\")\r\n",
                "if kube_config:\r\n",
                "    default_config_path = kube_config\r\n",
                "kube_config = input(\"Enter kube config. Default: %s\" % default_config_path) or default_config_path\r\n",
                "os.environ[\"KUBECONFIG\"] = kube_config\r\n",
                "print(\"Cluster Config Location: %s\" % kube_config)\r\n",
                "namespace = input(\"Enter Big data cluster name\")\r\n",
                "run_command('kubectl config set-context --current --namespace=%s' % namespace)"
            ],
            "metadata": {
                "azdata_cell_guid": "dde93e3c-6f20-48f7-88a9-0d3ec9cb455f"
            },
            "outputs": [],
            "execution_count": 3
        },
        {
            "cell_type": "code",
            "source": [
                "from pathlib import Path\r\n",
                "def find_file(file_name):\r\n",
                "    root = os.getcwd()\r\n",
                "    file_path = None\r\n",
                "    for filename in Path(root).rglob(file_name):\r\n",
                "        file_path = os.path.join(root, filename)\r\n",
                "        break\r\n",
                "    return file_path"
            ],
            "metadata": {
                "azdata_cell_guid": "f747a7f6-d62e-4cf4-b72c-1492d0b4dd56"
            },
            "outputs": [],
            "execution_count": 23
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Deploy MLFlow Container**\r\n",
                "Deploy an MLFlow container in your Big Data Cluster"
            ],
            "metadata": {
                "azdata_cell_guid": "720c200c-322a-49dd-9aa3-8bf7946aa251"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "config_file = find_file('mlflow-aks.yaml')\r\n",
                "run_command('kubectl apply -f \"%s\" -n %s' % (config_file, namespace))"
            ],
            "metadata": {
                "azdata_cell_guid": "dbdbb3d9-aa80-43ac-a387-05ddee01a958",
                "tags": []
            },
            "outputs": [],
            "execution_count": 14
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Get MLFlow container endpoint**"
            ],
            "metadata": {
                "azdata_cell_guid": "e33d6e1e-8c97-40dd-a4c2-77dddc0994e9"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "\r\n",
                "mlflow_ip = None\r\n",
                "mlflow_port = None\r\n",
                "for i in range(1, 50):\r\n",
                "    mlflow_ip = run_command('kubectl get service mlflow-svc -o=jsonpath=\"{.status.loadBalancer.ingress[0].ip}\" -n ' + namespace)\r\n",
                "    mlflow_port = run_command('kubectl get service mlflow-svc -o=jsonpath=\"{.spec.ports[0].port}\" -n ' + namespace)\r\n",
                "    print(mlflow_ip)\r\n",
                "    if not mlflow_ip:\r\n",
                "        time.sleep(50)\r\n",
                "    else:\r\n",
                "        break\r\n",
                "service_endpoint = None\r\n",
                "if mlflow_ip and mlflow_port:\r\n",
                "    service_endpoint = 'http://%s:%s' %(mlflow_ip, mlflow_port)\r\n",
                "\r\n",
                "else:\r\n",
                "    print('Failed to get MLFlow service endpoint')\r\n",
                "\r\n",
                "def make_clickable(val):\r\n",
                "    return '<a href=\"{}\">{}</a>'.format(val,val)\r\n",
                "df = pandas.DataFrame([service_endpoint])\r\n",
                "df.style.format(make_clickable)\r\n",
                "\r\n",
                ""
            ],
            "metadata": {
                "azdata_cell_guid": "68a84ca3-b272-4db7-a8dd-056a4a51e656"
            },
            "outputs": [],
            "execution_count": 17
        },
        {
            "cell_type": "markdown",
            "source": [
                "You can access your MLFlow container at this url."
            ],
            "metadata": {
                "azdata_cell_guid": "15aecb38-5487-4dac-994f-2145bf674d24"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Install the MLFlow client inside BDC**"
            ],
            "metadata": {
                "azdata_cell_guid": "32187207-7408-4335-b99a-9aed8d0b2f5c"
            }
        },
        {
            "cell_type": "markdown",
            "source": [
                "Get the number of replicas"
            ],
            "metadata": {
                "azdata_cell_guid": "8b25f6e8-30b4-40bf-acaa-791771e02bfd"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "replicas = run_command('kubectl get sts storage-0 -n %s -o=jsonpath=\"{.status.replicas}\" ' % namespace)"
            ],
            "metadata": {
                "azdata_cell_guid": "8100fb59-8a8e-40a0-87b1-c61aa4992ce2"
            },
            "outputs": [],
            "execution_count": 21
        },
        {
            "cell_type": "markdown",
            "source": [
                "Copy and install the MLFlow package"
            ],
            "metadata": {
                "azdata_cell_guid": "fb75b0e7-35bb-4796-81bf-6809ac599d4f"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "package_file = find_file('mlflow-1.1.1.dev0-py3-none-any.whl')\r\n",
                "for i in range(0, int(replicas)):\r\n",
                "    pod_name = \"storage-0-%s\" % str(i)\r\n",
                "    print('Installing MLFlow in %s' % pod_name)\r\n",
                "    run_command('kubectl cp \"%s\" -c hadoop %s:/var/mlflow-1.1.1.dev0-py3-none-any.whl -n %s' % (package_file, pod_name, namespace))\r\n",
                "    run_command('kubectl exec -ti %s -c hadoop -n %s -- pip3 install /var/mlflow-1.1.1.dev0-py3-none-any.whl' % (pod_name, namespace))"
            ],
            "metadata": {
                "azdata_cell_guid": "f237cdf7-1dbc-4a27-8919-aecc0a4f4f0c"
            },
            "outputs": [],
            "execution_count": 24
        },
        {
            "cell_type": "markdown",
            "source": [
                "### **Install MLFlow inside Azure Data Studio**"
            ],
            "metadata": {
                "azdata_cell_guid": "46b1f210-e087-4bc8-9bcf-86fb93462194"
            }
        },
        {
            "cell_type": "code",
            "source": [
                "run_command('pip install %s' % package_file)"
            ],
            "metadata": {
                "azdata_cell_guid": "07bd986b-dbd9-4427-b7e6-6dbd5ac8bf52"
            },
            "outputs": [],
            "execution_count": 25
        },
        {
            "cell_type": "markdown",
            "source": [
                "Now, you can use and access MLFlow from Azure Data Studio."
            ],
            "metadata": {
                "azdata_cell_guid": "0b8617e9-c362-4168-8579-354ffc58ccad"
            }
        }
    ]
}